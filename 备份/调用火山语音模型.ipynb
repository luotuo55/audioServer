{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402be328",
   "metadata": {},
   "outputs": [],
   "source": [
    "直接调用本地音频，调用火山平台的流式语音识别API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50338df6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_991/698042317.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/asyncio/runners.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         raise RuntimeError(\n\u001b[0;32m---> 34\u001b[0;31m             \"asyncio.run() cannot be called from a running event loop\")\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcoroutines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miscoroutine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\n",
    "\"\"\"\n",
    "requires Python 3.6 or later\n",
    "\n",
    "pip install asyncio\n",
    "pip install websockets\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import base64\n",
    "import gzip\n",
    "import hmac\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import wave\n",
    "from enum import Enum\n",
    "from hashlib import sha256\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import websockets\n",
    "\n",
    "# 火山平台API配置\n",
    "appid = \"4166554764\"    # 项目的 appid\n",
    "token = \"ggmUTHHMXio-nJlKMkRvqEgkcWyfDK0K\"    # 项目的 token\n",
    "cluster = \"volcengine_streaming_common\"  # 请求的集群\n",
    "\n",
    "# 获取当前脚本的目录\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "audio_path = os.path.join(current_dir, \"kangqiao.wav\")\n",
    "audio_format = \"wav\"\n",
    "\n",
    "print(f\"Audio file path: {audio_path}\")\n",
    "print(f\"Audio file exists: {os.path.exists(audio_path)}\")\n",
    "\n",
    "PROTOCOL_VERSION = 0b0001\n",
    "DEFAULT_HEADER_SIZE = 0b0001\n",
    "\n",
    "PROTOCOL_VERSION_BITS = 4\n",
    "HEADER_BITS = 4\n",
    "MESSAGE_TYPE_BITS = 4\n",
    "MESSAGE_TYPE_SPECIFIC_FLAGS_BITS = 4\n",
    "MESSAGE_SERIALIZATION_BITS = 4\n",
    "MESSAGE_COMPRESSION_BITS = 4\n",
    "RESERVED_BITS = 8\n",
    "\n",
    "# Message Type:\n",
    "CLIENT_FULL_REQUEST = 0b0001\n",
    "CLIENT_AUDIO_ONLY_REQUEST = 0b0010\n",
    "SERVER_FULL_RESPONSE = 0b1001\n",
    "SERVER_ACK = 0b1011\n",
    "SERVER_ERROR_RESPONSE = 0b1111\n",
    "\n",
    "# Message Type Specific Flags\n",
    "NO_SEQUENCE = 0b0000  # no check sequence\n",
    "POS_SEQUENCE = 0b0001\n",
    "NEG_SEQUENCE = 0b0010\n",
    "NEG_SEQUENCE_1 = 0b0011\n",
    "\n",
    "# Message Serialization\n",
    "NO_SERIALIZATION = 0b0000\n",
    "JSON = 0b0001\n",
    "THRIFT = 0b0011\n",
    "CUSTOM_TYPE = 0b1111\n",
    "\n",
    "# Message Compression\n",
    "NO_COMPRESSION = 0b0000\n",
    "GZIP = 0b0001\n",
    "CUSTOM_COMPRESSION = 0b1111\n",
    "\n",
    "\n",
    "def generate_header(\n",
    "    version=PROTOCOL_VERSION,\n",
    "    message_type=CLIENT_FULL_REQUEST,\n",
    "    message_type_specific_flags=NO_SEQUENCE,\n",
    "    serial_method=JSON,\n",
    "    compression_type=GZIP,\n",
    "    reserved_data=0x00,\n",
    "    extension_header=bytes()\n",
    "):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    \"\"\"\n",
    "    header = bytearray()\n",
    "    header_size = int(len(extension_header) / 4) + 1\n",
    "    header.append((version << 4) | header_size)\n",
    "    header.append((message_type << 4) | message_type_specific_flags)\n",
    "    header.append((serial_method << 4) | compression_type)\n",
    "    header.append(reserved_data)\n",
    "    header.extend(extension_header)\n",
    "    return header\n",
    "\n",
    "\n",
    "def generate_full_default_header():\n",
    "    return generate_header()\n",
    "\n",
    "\n",
    "def generate_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_last_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST,\n",
    "        message_type_specific_flags=NEG_SEQUENCE\n",
    "    )\n",
    "\n",
    "def parse_response(res):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    payload 类似与http 请求体\n",
    "    \"\"\"\n",
    "    protocol_version = res[0] >> 4\n",
    "    header_size = res[0] & 0x0f\n",
    "    message_type = res[1] >> 4\n",
    "    message_type_specific_flags = res[1] & 0x0f\n",
    "    serialization_method = res[2] >> 4\n",
    "    message_compression = res[2] & 0x0f\n",
    "    reserved = res[3]\n",
    "    header_extensions = res[4:header_size * 4]\n",
    "    payload = res[header_size * 4:]\n",
    "    result = {}\n",
    "    payload_msg = None\n",
    "    payload_size = 0\n",
    "    if message_type == SERVER_FULL_RESPONSE:\n",
    "        payload_size = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        payload_msg = payload[4:]\n",
    "    elif message_type == SERVER_ACK:\n",
    "        seq = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        result['seq'] = seq\n",
    "        if len(payload) >= 8:\n",
    "            payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "            payload_msg = payload[8:]\n",
    "    elif message_type == SERVER_ERROR_RESPONSE:\n",
    "        code = int.from_bytes(payload[:4], \"big\", signed=False)\n",
    "        result['code'] = code\n",
    "        payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "        payload_msg = payload[8:]\n",
    "    if payload_msg is None:\n",
    "        return result\n",
    "    if message_compression == GZIP:\n",
    "        payload_msg = gzip.decompress(payload_msg)\n",
    "    if serialization_method == JSON:\n",
    "        payload_msg = json.loads(str(payload_msg, \"utf-8\"))\n",
    "    elif serialization_method != NO_SERIALIZATION:\n",
    "        payload_msg = str(payload_msg, \"utf-8\")\n",
    "    result['payload_msg'] = payload_msg\n",
    "    result['payload_size'] = payload_size\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_wav_info(data: bytes = None) -> (int, int, int, int, int):\n",
    "    with BytesIO(data) as _f:\n",
    "        wave_fp = wave.open(_f, 'rb')\n",
    "        nchannels, sampwidth, framerate, nframes = wave_fp.getparams()[:4]\n",
    "        wave_bytes = wave_fp.readframes(nframes)\n",
    "    return nchannels, sampwidth, framerate, nframes, len(wave_bytes)\n",
    "\n",
    "class AudioType(Enum):\n",
    "    LOCAL = 1  # 使用本地音频文件\n",
    "\n",
    "class AsrWsClient:\n",
    "    def __init__(self, audio_path, cluster, **kwargs):\n",
    "        print(f\"Initializing AsrWsClient with audio_path: {audio_path}\")\n",
    "        self.audio_path = audio_path\n",
    "        self.cluster = cluster\n",
    "        self.success_code = 1000  # success code, default is 1000\n",
    "        self.seg_duration = int(kwargs.get(\"seg_duration\", 15000))\n",
    "        self.nbest = int(kwargs.get(\"nbest\", 1))\n",
    "        self.appid = kwargs.get(\"appid\", \"\")\n",
    "        self.token = kwargs.get(\"token\", \"\")\n",
    "        self.ws_url = kwargs.get(\"ws_url\", \"wss://openspeech.bytedance.com/api/v2/asr\")\n",
    "        self.uid = kwargs.get(\"uid\", \"streaming_asr_demo\")\n",
    "        self.workflow = kwargs.get(\"workflow\", \"audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate\")\n",
    "        self.show_language = kwargs.get(\"show_language\", False)\n",
    "        self.show_utterances = kwargs.get(\"show_utterances\", False)\n",
    "        self.result_type = kwargs.get(\"result_type\", \"full\")\n",
    "        self.format = kwargs.get(\"format\", \"wav\")\n",
    "        self.rate = kwargs.get(\"sample_rate\", 16000)\n",
    "        self.language = kwargs.get(\"language\", \"zh-CN\")\n",
    "        self.bits = kwargs.get(\"bits\", 16)\n",
    "        self.channel = kwargs.get(\"channel\", 1)\n",
    "        self.codec = kwargs.get(\"codec\", \"raw\")\n",
    "        self.audio_type = kwargs.get(\"audio_type\", AudioType.LOCAL)\n",
    "        self.secret = kwargs.get(\"secret\", \"access_secret\")\n",
    "        self.auth_method = kwargs.get(\"auth_method\", \"token\")\n",
    "        self.mp3_seg_size = int(kwargs.get(\"mp3_seg_size\", 10000))\n",
    "\n",
    "    def construct_request(self, reqid):\n",
    "        req = {\n",
    "            'app': {\n",
    "                'appid': self.appid,\n",
    "                'cluster': self.cluster,\n",
    "                'token': self.token,\n",
    "            },\n",
    "            'user': {\n",
    "                'uid': self.uid\n",
    "            },\n",
    "            'request': {\n",
    "                'reqid': reqid,\n",
    "                'nbest': self.nbest,\n",
    "                'workflow': self.workflow,\n",
    "                'show_language': self.show_language,\n",
    "                'show_utterances': self.show_utterances,\n",
    "                'result_type': self.result_type,\n",
    "                \"sequence\": 1\n",
    "            },\n",
    "            'audio': {\n",
    "                'format': self.format,\n",
    "                'rate': self.rate,\n",
    "                'language': self.language,\n",
    "                'bits': self.bits,\n",
    "                'channel': self.channel,\n",
    "                'codec': self.codec\n",
    "            }\n",
    "        }\n",
    "        return req\n",
    "\n",
    "    @staticmethod\n",
    "    def slice_data(data: bytes, chunk_size: int) -> (list, bool):\n",
    "        \"\"\"\n",
    "        slice data\n",
    "        :param data: wav data\n",
    "        :param chunk_size: the segment size in one request\n",
    "        :return: segment data, last flag\n",
    "        \"\"\"\n",
    "        data_len = len(data)\n",
    "        offset = 0\n",
    "        while offset + chunk_size < data_len:\n",
    "            yield data[offset: offset + chunk_size], False\n",
    "            offset += chunk_size\n",
    "        else:\n",
    "            yield data[offset: data_len], True\n",
    "\n",
    "    def _real_processor(self, request_params: dict) -> dict:\n",
    "        pass\n",
    "\n",
    "    def token_auth(self):\n",
    "        return {'Authorization': 'Bearer; {}'.format(self.token)}\n",
    "\n",
    "    def signature_auth(self, data):\n",
    "        header_dicts = {\n",
    "            'Custom': 'auth_custom',\n",
    "        }\n",
    "\n",
    "        url_parse = urlparse(self.ws_url)\n",
    "        input_str = 'GET {} HTTP/1.1\\n'.format(url_parse.path)\n",
    "        auth_headers = 'Custom'\n",
    "        for header in auth_headers.split(','):\n",
    "            input_str += '{}\\n'.format(header_dicts[header])\n",
    "        input_data = bytearray(input_str, 'utf-8')\n",
    "        input_data += data\n",
    "        mac = base64.urlsafe_b64encode(\n",
    "            hmac.new(self.secret.encode('utf-8'), input_data, digestmod=sha256).digest())\n",
    "        header_dicts['Authorization'] = 'HMAC256; access_token=\"{}\"; mac=\"{}\"; h=\"{}\"'.format(self.token,\n",
    "                                                                                              str(mac, 'utf-8'), auth_headers)\n",
    "        return header_dicts\n",
    "\n",
    "    async def segment_data_processor(self, wav_data: bytes, segment_size: int):\n",
    "        reqid = str(uuid.uuid4())\n",
    "        # 构建 full client request，序列化压缩\n",
    "        request_params = self.construct_request(reqid)\n",
    "        payload_bytes = str.encode(json.dumps(request_params))\n",
    "        payload_bytes = gzip.compress(payload_bytes)\n",
    "        full_client_request = bytearray(generate_full_default_header())\n",
    "        full_client_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "        full_client_request.extend(payload_bytes)  # payload\n",
    "        header = None\n",
    "        if self.auth_method == \"token\":\n",
    "            header = self.token_auth()\n",
    "        elif self.auth_method == \"signature\":\n",
    "            header = self.signature_auth(full_client_request)\n",
    "        async with websockets.connect(self.ws_url, extra_headers=header, max_size=1000000000) as ws:\n",
    "            # 发送 full client request\n",
    "            await ws.send(full_client_request)\n",
    "            res = await ws.recv()\n",
    "            result = parse_response(res)\n",
    "            if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                return result\n",
    "            for seq, (chunk, last) in enumerate(AsrWsClient.slice_data(wav_data, segment_size), 1):\n",
    "                # if no compression, comment this line\n",
    "                payload_bytes = gzip.compress(chunk)\n",
    "                audio_only_request = bytearray(generate_audio_default_header())\n",
    "                if last:\n",
    "                    audio_only_request = bytearray(generate_last_audio_default_header())\n",
    "                audio_only_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "                audio_only_request.extend(payload_bytes)  # payload\n",
    "                # 发送 audio-only client request\n",
    "                await ws.send(audio_only_request)\n",
    "                res = await ws.recv()\n",
    "                result = parse_response(res)\n",
    "                if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                    return result\n",
    "        return result\n",
    "\n",
    "    async def execute(self):\n",
    "        print(f\"Executing with audio_path: {self.audio_path}\")\n",
    "        with open(self.audio_path, mode=\"rb\") as _f:\n",
    "            data = _f.read()\n",
    "        audio_data = bytes(data)\n",
    "        if self.format == \"mp3\":\n",
    "            segment_size = self.mp3_seg_size\n",
    "            return await self.segment_data_processor(audio_data, segment_size)\n",
    "        if self.format != \"wav\":\n",
    "            raise Exception(\"format should in wav or mp3\")\n",
    "        nchannels, sampwidth, framerate, nframes, wav_len = read_wav_info(\n",
    "            audio_data)\n",
    "        size_per_sec = nchannels * sampwidth * framerate\n",
    "        segment_size = int(size_per_sec * self.seg_duration / 1000)\n",
    "        return await self.segment_data_processor(audio_data, segment_size)\n",
    "\n",
    "\n",
    "def execute_one(audio_item, cluster, **kwargs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param audio_item: {\"id\": xxx, \"path\": \"xxx\"}\n",
    "    :param cluster:集群名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert 'id' in audio_item\n",
    "    assert 'path' in audio_item\n",
    "    audio_id = audio_item['id']\n",
    "    audio_path = audio_item['path']\n",
    "    audio_type = AudioType.LOCAL\n",
    "    asr_http_client = AsrWsClient(\n",
    "        audio_path=audio_path,  # 确保这里使用了正确的 audio_path\n",
    "        cluster=cluster,\n",
    "        audio_type=audio_type,\n",
    "        **kwargs\n",
    "    )\n",
    "    result = asyncio.run(asr_http_client.execute())\n",
    "    return {\"id\": audio_id, \"path\": audio_path, \"result\": result}\n",
    "\n",
    "def test_one():\n",
    "    result = execute_one(\n",
    "        {\n",
    "            'id': 1,\n",
    "            'path': audio_path\n",
    "        },\n",
    "        cluster=cluster,\n",
    "        appid=appid,\n",
    "        token=token,\n",
    "        format=audio_format,\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_one()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "为以上代码添加录音功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0af9180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始录音...\n",
      "录音将在 3 秒后开始...\n",
      "录音将在 2 秒后开始...\n",
      "录音将在 1 秒后开始...\n",
      "正在录音，持续 6 秒...\n",
      "录音完成，文件已保存\n",
      "开始处理音频文件: temp_recording.wav\n",
      "Initializing AsrWsClient with audio_path: temp_recording.wav\n",
      "Executing with audio_path: temp_recording.wav\n",
      "Raw result: {'id': 1, 'path': 'temp_recording.wav', 'result': {'payload_msg': {'addition': {'duration': '5632', 'logid': '2024102510542047FFF69A9234E524AB9C', 'split_time': '[]'}, 'code': 1000, 'message': 'Success', 'reqid': '0a75e06a-cfe7-4b7b-90b5-f1d49e2af2e1', 'result': [{'confidence': 0, 'text': '我走了。 正如我轻轻的。'}], 'sequence': -2}, 'payload_size': 252}}\n",
      "\n",
      "识别结果:\n",
      "我走了。 正如我轻轻的。\n",
      "第1段置信度: 0\n",
      "临时音频文件已删除\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "requires Python 3.6 or later\n",
    "\n",
    "pip install asyncio\n",
    "pip install websockets\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import base64\n",
    "import gzip\n",
    "import hmac\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import wave\n",
    "from enum import Enum\n",
    "from hashlib import sha256\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import websockets\n",
    "from unihiker import Audio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 火山平台API配置\n",
    "appid = \"4166554764\"    # 项目的 appid\n",
    "token = \"ggmUTHHMXio-nJlKMkRvqEgkcWyfDK0K\"    # 项目的 token\n",
    "cluster = \"volcengine_streaming_common\"  # 请求的集群\n",
    "\n",
    "# 音频采集设置\n",
    "RECORD_DURATION = 6  # 录音时长(秒)\n",
    "TEMP_AUDIO_FILE = \"temp_recording.wav\"  # 临时音频文件名\n",
    "\n",
    "PROTOCOL_VERSION = 0b0001\n",
    "DEFAULT_HEADER_SIZE = 0b0001\n",
    "\n",
    "PROTOCOL_VERSION_BITS = 4\n",
    "HEADER_BITS = 4\n",
    "MESSAGE_TYPE_BITS = 4\n",
    "MESSAGE_TYPE_SPECIFIC_FLAGS_BITS = 4\n",
    "MESSAGE_SERIALIZATION_BITS = 4\n",
    "MESSAGE_COMPRESSION_BITS = 4\n",
    "RESERVED_BITS = 8\n",
    "\n",
    "# Message Type:\n",
    "CLIENT_FULL_REQUEST = 0b0001\n",
    "CLIENT_AUDIO_ONLY_REQUEST = 0b0010\n",
    "SERVER_FULL_RESPONSE = 0b1001\n",
    "SERVER_ACK = 0b1011\n",
    "SERVER_ERROR_RESPONSE = 0b1111\n",
    "\n",
    "# Message Type Specific Flags\n",
    "NO_SEQUENCE = 0b0000  # no check sequence\n",
    "POS_SEQUENCE = 0b0001\n",
    "NEG_SEQUENCE = 0b0010\n",
    "NEG_SEQUENCE_1 = 0b0011\n",
    "\n",
    "# Message Serialization\n",
    "NO_SERIALIZATION = 0b0000\n",
    "JSON = 0b0001\n",
    "THRIFT = 0b0011\n",
    "CUSTOM_TYPE = 0b1111\n",
    "\n",
    "# Message Compression\n",
    "NO_COMPRESSION = 0b0000\n",
    "GZIP = 0b0001\n",
    "CUSTOM_COMPRESSION = 0b1111\n",
    "\n",
    "\n",
    "def generate_header(\n",
    "    version=PROTOCOL_VERSION,\n",
    "    message_type=CLIENT_FULL_REQUEST,\n",
    "    message_type_specific_flags=NO_SEQUENCE,\n",
    "    serial_method=JSON,\n",
    "    compression_type=GZIP,\n",
    "    reserved_data=0x00,\n",
    "    extension_header=bytes()\n",
    "):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    \"\"\"\n",
    "    header = bytearray()\n",
    "    header_size = int(len(extension_header) / 4) + 1\n",
    "    header.append((version << 4) | header_size)\n",
    "    header.append((message_type << 4) | message_type_specific_flags)\n",
    "    header.append((serial_method << 4) | compression_type)\n",
    "    header.append(reserved_data)\n",
    "    header.extend(extension_header)\n",
    "    return header\n",
    "\n",
    "\n",
    "def generate_full_default_header():\n",
    "    return generate_header()\n",
    "\n",
    "\n",
    "def generate_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_last_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST,\n",
    "        message_type_specific_flags=NEG_SEQUENCE\n",
    "    )\n",
    "\n",
    "def parse_response(res):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    payload 类似与http 请求体\n",
    "    \"\"\"\n",
    "    protocol_version = res[0] >> 4\n",
    "    header_size = res[0] & 0x0f\n",
    "    message_type = res[1] >> 4\n",
    "    message_type_specific_flags = res[1] & 0x0f\n",
    "    serialization_method = res[2] >> 4\n",
    "    message_compression = res[2] & 0x0f\n",
    "    reserved = res[3]\n",
    "    header_extensions = res[4:header_size * 4]\n",
    "    payload = res[header_size * 4:]\n",
    "    result = {}\n",
    "    payload_msg = None\n",
    "    payload_size = 0\n",
    "    if message_type == SERVER_FULL_RESPONSE:\n",
    "        payload_size = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        payload_msg = payload[4:]\n",
    "    elif message_type == SERVER_ACK:\n",
    "        seq = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        result['seq'] = seq\n",
    "        if len(payload) >= 8:\n",
    "            payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "            payload_msg = payload[8:]\n",
    "    elif message_type == SERVER_ERROR_RESPONSE:\n",
    "        code = int.from_bytes(payload[:4], \"big\", signed=False)\n",
    "        result['code'] = code\n",
    "        payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "        payload_msg = payload[8:]\n",
    "    if payload_msg is None:\n",
    "        return result\n",
    "    if message_compression == GZIP:\n",
    "        payload_msg = gzip.decompress(payload_msg)\n",
    "    if serialization_method == JSON:\n",
    "        payload_msg = json.loads(str(payload_msg, \"utf-8\"))\n",
    "    elif serialization_method != NO_SERIALIZATION:\n",
    "        payload_msg = str(payload_msg, \"utf-8\")\n",
    "    result['payload_msg'] = payload_msg\n",
    "    result['payload_size'] = payload_size\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_wav_info(data: bytes = None) -> (int, int, int, int, int):\n",
    "    with BytesIO(data) as _f:\n",
    "        wave_fp = wave.open(_f, 'rb')\n",
    "        nchannels, sampwidth, framerate, nframes = wave_fp.getparams()[:4]\n",
    "        wave_bytes = wave_fp.readframes(nframes)\n",
    "    return nchannels, sampwidth, framerate, nframes, len(wave_bytes)\n",
    "\n",
    "class AudioType(Enum):\n",
    "    LOCAL = 1  # 使用本地音频文件\n",
    "\n",
    "class AsrWsClient:\n",
    "    def __init__(self, audio_path, cluster, **kwargs):\n",
    "        print(f\"Initializing AsrWsClient with audio_path: {audio_path}\")\n",
    "        self.audio_path = audio_path\n",
    "        self.cluster = cluster\n",
    "        self.success_code = 1000  # success code, default is 1000\n",
    "        self.seg_duration = int(kwargs.get(\"seg_duration\", 15000))\n",
    "        self.nbest = int(kwargs.get(\"nbest\", 1))\n",
    "        self.appid = kwargs.get(\"appid\", \"\")\n",
    "        self.token = kwargs.get(\"token\", \"\")\n",
    "        self.ws_url = kwargs.get(\"ws_url\", \"wss://openspeech.bytedance.com/api/v2/asr\")\n",
    "        self.uid = kwargs.get(\"uid\", \"streaming_asr_demo\")\n",
    "        self.workflow = kwargs.get(\"workflow\", \"audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate\")\n",
    "        self.show_language = kwargs.get(\"show_language\", False)\n",
    "        self.show_utterances = kwargs.get(\"show_utterances\", False)\n",
    "        self.result_type = kwargs.get(\"result_type\", \"full\")\n",
    "        self.format = kwargs.get(\"format\", \"wav\")\n",
    "        self.rate = kwargs.get(\"sample_rate\", 16000)\n",
    "        self.language = kwargs.get(\"language\", \"zh-CN\")\n",
    "        self.bits = kwargs.get(\"bits\", 16)\n",
    "        self.channel = kwargs.get(\"channel\", 1)\n",
    "        self.codec = kwargs.get(\"codec\", \"raw\")\n",
    "        self.audio_type = kwargs.get(\"audio_type\", AudioType.LOCAL)\n",
    "        self.secret = kwargs.get(\"secret\", \"access_secret\")\n",
    "        self.auth_method = kwargs.get(\"auth_method\", \"token\")\n",
    "        self.mp3_seg_size = int(kwargs.get(\"mp3_seg_size\", 10000))\n",
    "\n",
    "    def construct_request(self, reqid):\n",
    "        req = {\n",
    "            'app': {\n",
    "                'appid': self.appid,\n",
    "                'cluster': self.cluster,\n",
    "                'token': self.token,\n",
    "            },\n",
    "            'user': {\n",
    "                'uid': self.uid\n",
    "            },\n",
    "            'request': {\n",
    "                'reqid': reqid,\n",
    "                'nbest': self.nbest,\n",
    "                'workflow': self.workflow,\n",
    "                'show_language': self.show_language,\n",
    "                'show_utterances': self.show_utterances,\n",
    "                'result_type': self.result_type,\n",
    "                \"sequence\": 1\n",
    "            },\n",
    "            'audio': {\n",
    "                'format': self.format,\n",
    "                'rate': self.rate,\n",
    "                'language': self.language,\n",
    "                'bits': self.bits,\n",
    "                'channel': self.channel,\n",
    "                'codec': self.codec\n",
    "            }\n",
    "        }\n",
    "        return req\n",
    "\n",
    "    @staticmethod\n",
    "    def slice_data(data: bytes, chunk_size: int) -> (list, bool):\n",
    "        \"\"\"\n",
    "        slice data\n",
    "        :param data: wav data\n",
    "        :param chunk_size: the segment size in one request\n",
    "        :return: segment data, last flag\n",
    "        \"\"\"\n",
    "        data_len = len(data)\n",
    "        offset = 0\n",
    "        while offset + chunk_size < data_len:\n",
    "            yield data[offset: offset + chunk_size], False\n",
    "            offset += chunk_size\n",
    "        else:\n",
    "            yield data[offset: data_len], True\n",
    "\n",
    "    def _real_processor(self, request_params: dict) -> dict:\n",
    "        pass\n",
    "\n",
    "    def token_auth(self):\n",
    "        return {'Authorization': 'Bearer; {}'.format(self.token)}\n",
    "\n",
    "    def signature_auth(self, data):\n",
    "        header_dicts = {\n",
    "            'Custom': 'auth_custom',\n",
    "        }\n",
    "\n",
    "        url_parse = urlparse(self.ws_url)\n",
    "        input_str = 'GET {} HTTP/1.1\\n'.format(url_parse.path)\n",
    "        auth_headers = 'Custom'\n",
    "        for header in auth_headers.split(','):\n",
    "            input_str += '{}\\n'.format(header_dicts[header])\n",
    "        input_data = bytearray(input_str, 'utf-8')\n",
    "        input_data += data\n",
    "        mac = base64.urlsafe_b64encode(\n",
    "            hmac.new(self.secret.encode('utf-8'), input_data, digestmod=sha256).digest())\n",
    "        header_dicts['Authorization'] = 'HMAC256; access_token=\"{}\"; mac=\"{}\"; h=\"{}\"'.format(self.token,\n",
    "                                                                                              str(mac, 'utf-8'), auth_headers)\n",
    "        return header_dicts\n",
    "\n",
    "    async def segment_data_processor(self, wav_data: bytes, segment_size: int):\n",
    "        reqid = str(uuid.uuid4())\n",
    "        # 构建 full client request，序列化压缩\n",
    "        request_params = self.construct_request(reqid)\n",
    "        payload_bytes = str.encode(json.dumps(request_params))\n",
    "        payload_bytes = gzip.compress(payload_bytes)\n",
    "        full_client_request = bytearray(generate_full_default_header())\n",
    "        full_client_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "        full_client_request.extend(payload_bytes)  # payload\n",
    "        header = None\n",
    "        if self.auth_method == \"token\":\n",
    "            header = self.token_auth()\n",
    "        elif self.auth_method == \"signature\":\n",
    "            header = self.signature_auth(full_client_request)\n",
    "        async with websockets.connect(self.ws_url, extra_headers=header, max_size=1000000000) as ws:\n",
    "            # 发送 full client request\n",
    "            await ws.send(full_client_request)\n",
    "            res = await ws.recv()\n",
    "            result = parse_response(res)\n",
    "            if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                return result\n",
    "            for seq, (chunk, last) in enumerate(AsrWsClient.slice_data(wav_data, segment_size), 1):\n",
    "                # if no compression, comment this line\n",
    "                payload_bytes = gzip.compress(chunk)\n",
    "                audio_only_request = bytearray(generate_audio_default_header())\n",
    "                if last:\n",
    "                    audio_only_request = bytearray(generate_last_audio_default_header())\n",
    "                audio_only_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "                audio_only_request.extend(payload_bytes)  # payload\n",
    "                # 发送 audio-only client request\n",
    "                await ws.send(audio_only_request)\n",
    "                res = await ws.recv()\n",
    "                result = parse_response(res)\n",
    "                if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                    return result\n",
    "        return result\n",
    "\n",
    "    async def execute(self):\n",
    "        print(f\"Executing with audio_path: {self.audio_path}\")\n",
    "        with open(self.audio_path, mode=\"rb\") as _f:\n",
    "            data = _f.read()\n",
    "        audio_data = bytes(data)\n",
    "        if self.format == \"mp3\":\n",
    "            segment_size = self.mp3_seg_size\n",
    "            return await self.segment_data_processor(audio_data, segment_size)\n",
    "        if self.format != \"wav\":\n",
    "            raise Exception(\"format should in wav or mp3\")\n",
    "        nchannels, sampwidth, framerate, nframes, wav_len = read_wav_info(\n",
    "            audio_data)\n",
    "        size_per_sec = nchannels * sampwidth * framerate\n",
    "        segment_size = int(size_per_sec * self.seg_duration / 1000)\n",
    "        return await self.segment_data_processor(audio_data, segment_size)\n",
    "\n",
    "\n",
    "def execute_one(audio_item, cluster, **kwargs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param audio_item: {\"id\": xxx, \"path\": \"xxx\"}\n",
    "    :param cluster:集群名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert 'id' in audio_item\n",
    "    assert 'path' in audio_item\n",
    "    audio_id = audio_item['id']\n",
    "    audio_path = audio_item['path']\n",
    "    audio_type = AudioType.LOCAL\n",
    "    asr_http_client = AsrWsClient(\n",
    "        audio_path=audio_path,  # 确保这里使用了正确的 audio_path\n",
    "        cluster=cluster,\n",
    "        audio_type=audio_type,\n",
    "        **kwargs\n",
    "    )\n",
    "    result = asyncio.run(asr_http_client.execute())\n",
    "    return {\"id\": audio_id, \"path\": audio_path, \"result\": result}\n",
    "\n",
    "def test_one():\n",
    "    result = execute_one(\n",
    "        {\n",
    "            'id': 1,\n",
    "            'path': audio_path\n",
    "        },\n",
    "        cluster=cluster,\n",
    "        appid=appid,\n",
    "        token=token,\n",
    "        format=audio_format,\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"使用麦克风录制音频\"\"\"\n",
    "    print(\"开始录音...\")\n",
    "    audio = Audio()\n",
    "    \n",
    "    try:\n",
    "        # 显示录音倒计时\n",
    "        for i in range(3, 0, -1):\n",
    "            print(f\"录音将在 {i} 秒后开始...\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 开始录音\n",
    "        print(f\"正在录音，持续 {RECORD_DURATION} 秒...\")\n",
    "        audio.record(TEMP_AUDIO_FILE, RECORD_DURATION)\n",
    "        time.sleep(RECORD_DURATION + 0.5)  # 等待录音完成，多等待0.5秒确保文件保存\n",
    "        \n",
    "        # 检查文件是否成功创建\n",
    "        if os.path.exists(TEMP_AUDIO_FILE):\n",
    "            print(f\"录音完成，文件已保存为: {TEMP_AUDIO_FILE}\")\n",
    "            return TEMP_AUDIO_FILE\n",
    "        else:\n",
    "            print(\"录音文件创建失败\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"录音过程中发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "async def process_audio(audio_file):\n",
    "    \"\"\"处理录制的音频文件\"\"\"\n",
    "    print(f\"开始处理音频文件: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        result = execute_one(\n",
    "            {\n",
    "                'id': 1,\n",
    "                'path': audio_file\n",
    "            },\n",
    "            cluster=cluster,\n",
    "            appid=appid,\n",
    "            token=token,\n",
    "            format=\"wav\",\n",
    "        )\n",
    "        \n",
    "        print(\"Raw result:\", result)\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            if 'result' in result and isinstance(result['result'], dict):\n",
    "                payload_msg = result['result'].get('payload_msg', {})\n",
    "                if isinstance(payload_msg, dict):\n",
    "                    if payload_msg.get('code') == 1000:\n",
    "                        # 处理结果列表\n",
    "                        results = payload_msg.get('result', [])\n",
    "                        if results and isinstance(results, list):\n",
    "                            # 合并所有识别结果\n",
    "                            texts = [item.get('text', '') for item in results if isinstance(item, dict)]\n",
    "                            full_text = ''.join(texts)\n",
    "                            print(\"\\n识别结果:\")\n",
    "                            print(full_text)\n",
    "                            \n",
    "                            # 如果需要，也可以显示每段的置信度\n",
    "                            for i, item in enumerate(results, 1):\n",
    "                                if isinstance(item, dict):\n",
    "                                    confidence = item.get('confidence', 0)\n",
    "                                    print(f\"第{i}段置信度: {confidence}\")\n",
    "                        else:\n",
    "                            print(\"未获取到识别文本\")\n",
    "                    else:\n",
    "                        print(f\"\\n识别失败，错误码: {payload_msg.get('code')}\")\n",
    "                        print(f\"错误信息: {payload_msg.get('message', '无错误信息')}\")\n",
    "                else:\n",
    "                    print(\"无法解析 payload_msg\")\n",
    "            else:\n",
    "                print(\"无法获取识别结果\")\n",
    "                print(\"完整返回数据:\", result)\n",
    "        else:\n",
    "            print(\"返回数据格式错误\")\n",
    "            print(\"返回数据:\", result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"处理音频时发生错误: {str(e)}\")\n",
    "        print(\"错误类型:\", type(e))\n",
    "        import traceback\n",
    "        print(\"错误堆栈:\", traceback.format_exc())\n",
    "    finally:\n",
    "        # 清理临时音频文件\n",
    "        try:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.remove(audio_file)\n",
    "                print(\"临时音频文件已删除\")\n",
    "        except Exception as e:\n",
    "            print(f\"删除临时文件时发生错误: {e}\")\n",
    "\n",
    "async def single_recognition():\n",
    "    \"\"\"执行一次录音识别\"\"\"\n",
    "    print(\"开始录音...\")\n",
    "    audio = Audio()\n",
    "    audio_file = \"temp_recording.wav\"\n",
    "    \n",
    "    try:\n",
    "        # 倒计时\n",
    "        for i in range(3, 0, -1):\n",
    "            print(f\"录音将在 {i} 秒后开始...\")\n",
    "            await asyncio.sleep(1)\n",
    "        \n",
    "        # 开始录音\n",
    "        print(f\"正在录音，持续 6 秒...\")\n",
    "        audio.record(audio_file, 6)\n",
    "        await asyncio.sleep(6.5)  # 等待录音完成\n",
    "        \n",
    "        if os.path.exists(audio_file):\n",
    "            print(f\"录音完成，文件已保存\")\n",
    "            # 处理音频\n",
    "            await process_audio(audio_file)\n",
    "        else:\n",
    "            print(\"录音失败\")\n",
    "    except Exception as e:\n",
    "        print(f\"录音过程中发生错误: {e}\")\n",
    "\n",
    "# 在 Jupyter 中使用这个函数来执行一次识别\n",
    "async def run_once():\n",
    "    \"\"\"执行一次语音识别\"\"\"\n",
    "    await single_recognition()\n",
    "\n",
    "# 在 Jupyter 中这样使用：\n",
    "await run_once()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59d9114",
   "metadata": {},
   "outputs": [],
   "source": [
    "上面的代码是定时录音的，为上面的代码点击屏幕录音，点击屏幕结束录音的功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0346ea2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[状态] 程序已启动，等待操作...\n",
      "[状态] 开始录音\n",
      "[状态] 停止录音\n",
      "[状态] 开始处理音频文件: /tmp/recording.wav\n",
      "Initializing AsrWsClient with audio_path: /tmp/recording.wav\n",
      "Executing with audio_path: /tmp/recording.wav\n",
      "[状态] 识别结果: 蝶康桥。 徐志摩。 轻轻的。 我走了。 正如我轻轻的来。 我轻轻的招手。 作别西天的云彩。 那河畔。 的，金柳岸的。 是夕阳中的。\n",
      "[状态] 临时音频文件已删除\n",
      "[状态] 程序被用户中断\n",
      "[状态] 程序结束\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "requires Python 3.6 or later\n",
    "\n",
    "pip install asyncio\n",
    "pip install websockets\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import base64\n",
    "import gzip\n",
    "import hmac\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import wave\n",
    "from enum import Enum\n",
    "from hashlib import sha256\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import websockets\n",
    "from unihiker import Audio, GUI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import threading\n",
    "\n",
    "# 火山平台API配置\n",
    "appid = \"4166554764\"    # 项目的 appid\n",
    "token = \"ggmUTHHMXio-nJlKMkRvqEgkcWyfDK0K\"    # 项目的 token\n",
    "cluster = \"volcengine_streaming_common\"  # 请求的集群\n",
    "\n",
    "# 音频采集设置\n",
    "RECORD_DURATION = 6  # 录音时长(秒)\n",
    "TEMP_AUDIO_FILE = \"temp_recording.wav\"  # 临时音频文件名\n",
    "\n",
    "PROTOCOL_VERSION = 0b0001\n",
    "DEFAULT_HEADER_SIZE = 0b0001\n",
    "\n",
    "PROTOCOL_VERSION_BITS = 4\n",
    "HEADER_BITS = 4\n",
    "MESSAGE_TYPE_BITS = 4\n",
    "MESSAGE_TYPE_SPECIFIC_FLAGS_BITS = 4\n",
    "MESSAGE_SERIALIZATION_BITS = 4\n",
    "MESSAGE_COMPRESSION_BITS = 4\n",
    "RESERVED_BITS = 8\n",
    "\n",
    "# Message Type:\n",
    "CLIENT_FULL_REQUEST = 0b0001\n",
    "CLIENT_AUDIO_ONLY_REQUEST = 0b0010\n",
    "SERVER_FULL_RESPONSE = 0b1001\n",
    "SERVER_ACK = 0b1011\n",
    "SERVER_ERROR_RESPONSE = 0b1111\n",
    "\n",
    "# Message Type Specific Flags\n",
    "NO_SEQUENCE = 0b0000  # no check sequence\n",
    "POS_SEQUENCE = 0b0001\n",
    "NEG_SEQUENCE = 0b0010\n",
    "NEG_SEQUENCE_1 = 0b0011\n",
    "\n",
    "# Message Serialization\n",
    "NO_SERIALIZATION = 0b0000\n",
    "JSON = 0b0001\n",
    "THRIFT = 0b0011\n",
    "CUSTOM_TYPE = 0b1111\n",
    "\n",
    "# Message Compression\n",
    "NO_COMPRESSION = 0b0000\n",
    "GZIP = 0b0001\n",
    "CUSTOM_COMPRESSION = 0b1111\n",
    "\n",
    "\n",
    "def generate_header(\n",
    "    version=PROTOCOL_VERSION,\n",
    "    message_type=CLIENT_FULL_REQUEST,\n",
    "    message_type_specific_flags=NO_SEQUENCE,\n",
    "    serial_method=JSON,\n",
    "    compression_type=GZIP,\n",
    "    reserved_data=0x00,\n",
    "    extension_header=bytes()\n",
    "):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    \"\"\"\n",
    "    header = bytearray()\n",
    "    header_size = int(len(extension_header) / 4) + 1\n",
    "    header.append((version << 4) | header_size)\n",
    "    header.append((message_type << 4) | message_type_specific_flags)\n",
    "    header.append((serial_method << 4) | compression_type)\n",
    "    header.append(reserved_data)\n",
    "    header.extend(extension_header)\n",
    "    return header\n",
    "\n",
    "\n",
    "def generate_full_default_header():\n",
    "    return generate_header()\n",
    "\n",
    "\n",
    "def generate_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_last_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST,\n",
    "        message_type_specific_flags=NEG_SEQUENCE\n",
    "    )\n",
    "\n",
    "def parse_response(res):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    payload 类似与http 请求体\n",
    "    \"\"\"\n",
    "    protocol_version = res[0] >> 4\n",
    "    header_size = res[0] & 0x0f\n",
    "    message_type = res[1] >> 4\n",
    "    message_type_specific_flags = res[1] & 0x0f\n",
    "    serialization_method = res[2] >> 4\n",
    "    message_compression = res[2] & 0x0f\n",
    "    reserved = res[3]\n",
    "    header_extensions = res[4:header_size * 4]\n",
    "    payload = res[header_size * 4:]\n",
    "    result = {}\n",
    "    payload_msg = None\n",
    "    payload_size = 0\n",
    "    if message_type == SERVER_FULL_RESPONSE:\n",
    "        payload_size = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        payload_msg = payload[4:]\n",
    "    elif message_type == SERVER_ACK:\n",
    "        seq = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        result['seq'] = seq\n",
    "        if len(payload) >= 8:\n",
    "            payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "            payload_msg = payload[8:]\n",
    "    elif message_type == SERVER_ERROR_RESPONSE:\n",
    "        code = int.from_bytes(payload[:4], \"big\", signed=False)\n",
    "        result['code'] = code\n",
    "        payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "        payload_msg = payload[8:]\n",
    "    if payload_msg is None:\n",
    "        return result\n",
    "    if message_compression == GZIP:\n",
    "        payload_msg = gzip.decompress(payload_msg)\n",
    "    if serialization_method == JSON:\n",
    "        payload_msg = json.loads(str(payload_msg, \"utf-8\"))\n",
    "    elif serialization_method != NO_SERIALIZATION:\n",
    "        payload_msg = str(payload_msg, \"utf-8\")\n",
    "    result['payload_msg'] = payload_msg\n",
    "    result['payload_size'] = payload_size\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_wav_info(data: bytes = None) -> (int, int, int, int, int):\n",
    "    with BytesIO(data) as _f:\n",
    "        wave_fp = wave.open(_f, 'rb')\n",
    "        nchannels, sampwidth, framerate, nframes = wave_fp.getparams()[:4]\n",
    "        wave_bytes = wave_fp.readframes(nframes)\n",
    "    return nchannels, sampwidth, framerate, nframes, len(wave_bytes)\n",
    "\n",
    "class AudioType(Enum):\n",
    "    LOCAL = 1  # 使用本地音频文件\n",
    "\n",
    "class AsrWsClient:\n",
    "    def __init__(self, audio_path, cluster, **kwargs):\n",
    "        print(f\"Initializing AsrWsClient with audio_path: {audio_path}\")\n",
    "        self.audio_path = audio_path\n",
    "        self.cluster = cluster\n",
    "        self.success_code = 1000  # success code, default is 1000\n",
    "        self.seg_duration = int(kwargs.get(\"seg_duration\", 15000))\n",
    "        self.nbest = int(kwargs.get(\"nbest\", 1))\n",
    "        self.appid = kwargs.get(\"appid\", \"\")\n",
    "        self.token = kwargs.get(\"token\", \"\")\n",
    "        self.ws_url = kwargs.get(\"ws_url\", \"wss://openspeech.bytedance.com/api/v2/asr\")\n",
    "        self.uid = kwargs.get(\"uid\", \"streaming_asr_demo\")\n",
    "        self.workflow = kwargs.get(\"workflow\", \"audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate\")\n",
    "        self.show_language = kwargs.get(\"show_language\", False)\n",
    "        self.show_utterances = kwargs.get(\"show_utterances\", False)\n",
    "        self.result_type = kwargs.get(\"result_type\", \"full\")\n",
    "        self.format = kwargs.get(\"format\", \"wav\")\n",
    "        self.rate = kwargs.get(\"sample_rate\", 16000)\n",
    "        self.language = kwargs.get(\"language\", \"zh-CN\")\n",
    "        self.bits = kwargs.get(\"bits\", 16)\n",
    "        self.channel = kwargs.get(\"channel\", 1)\n",
    "        self.codec = kwargs.get(\"codec\", \"raw\")\n",
    "        self.audio_type = kwargs.get(\"audio_type\", AudioType.LOCAL)\n",
    "        self.secret = kwargs.get(\"secret\", \"access_secret\")\n",
    "        self.auth_method = kwargs.get(\"auth_method\", \"token\")\n",
    "        self.mp3_seg_size = int(kwargs.get(\"mp3_seg_size\", 10000))\n",
    "\n",
    "    def construct_request(self, reqid):\n",
    "        req = {\n",
    "            'app': {\n",
    "                'appid': self.appid,\n",
    "                'cluster': self.cluster,\n",
    "                'token': self.token,\n",
    "            },\n",
    "            'user': {\n",
    "                'uid': self.uid\n",
    "            },\n",
    "            'request': {\n",
    "                'reqid': reqid,\n",
    "                'nbest': self.nbest,\n",
    "                'workflow': self.workflow,\n",
    "                'show_language': self.show_language,\n",
    "                'show_utterances': self.show_utterances,\n",
    "                'result_type': self.result_type,\n",
    "                \"sequence\": 1\n",
    "            },\n",
    "            'audio': {\n",
    "                'format': self.format,\n",
    "                'rate': self.rate,\n",
    "                'language': self.language,\n",
    "                'bits': self.bits,\n",
    "                'channel': self.channel,\n",
    "                'codec': self.codec\n",
    "            }\n",
    "        }\n",
    "        return req\n",
    "\n",
    "    @staticmethod\n",
    "    def slice_data(data: bytes, chunk_size: int) -> (list, bool):\n",
    "        \"\"\"\n",
    "        slice data\n",
    "        :param data: wav data\n",
    "        :param chunk_size: the segment size in one request\n",
    "        :return: segment data, last flag\n",
    "        \"\"\"\n",
    "        data_len = len(data)\n",
    "        offset = 0\n",
    "        while offset + chunk_size < data_len:\n",
    "            yield data[offset: offset + chunk_size], False\n",
    "            offset += chunk_size\n",
    "        else:\n",
    "            yield data[offset: data_len], True\n",
    "\n",
    "    def _real_processor(self, request_params: dict) -> dict:\n",
    "        pass\n",
    "\n",
    "    def token_auth(self):\n",
    "        return {'Authorization': 'Bearer; {}'.format(self.token)}\n",
    "\n",
    "    def signature_auth(self, data):\n",
    "        header_dicts = {\n",
    "            'Custom': 'auth_custom',\n",
    "        }\n",
    "\n",
    "        url_parse = urlparse(self.ws_url)\n",
    "        input_str = 'GET {} HTTP/1.1\\n'.format(url_parse.path)\n",
    "        auth_headers = 'Custom'\n",
    "        for header in auth_headers.split(','):\n",
    "            input_str += '{}\\n'.format(header_dicts[header])\n",
    "        input_data = bytearray(input_str, 'utf-8')\n",
    "        input_data += data\n",
    "        mac = base64.urlsafe_b64encode(\n",
    "            hmac.new(self.secret.encode('utf-8'), input_data, digestmod=sha256).digest())\n",
    "        header_dicts['Authorization'] = 'HMAC256; access_token=\"{}\"; mac=\"{}\"; h=\"{}\"'.format(self.token,\n",
    "                                                                                              str(mac, 'utf-8'), auth_headers)\n",
    "        return header_dicts\n",
    "\n",
    "    async def segment_data_processor(self, wav_data: bytes, segment_size: int):\n",
    "        reqid = str(uuid.uuid4())\n",
    "        # 构建 full client request，序列化压缩\n",
    "        request_params = self.construct_request(reqid)\n",
    "        payload_bytes = str.encode(json.dumps(request_params))\n",
    "        payload_bytes = gzip.compress(payload_bytes)\n",
    "        full_client_request = bytearray(generate_full_default_header())\n",
    "        full_client_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "        full_client_request.extend(payload_bytes)  # payload\n",
    "        header = None\n",
    "        if self.auth_method == \"token\":\n",
    "            header = self.token_auth()\n",
    "        elif self.auth_method == \"signature\":\n",
    "            header = self.signature_auth(full_client_request)\n",
    "        async with websockets.connect(self.ws_url, extra_headers=header, max_size=1000000000) as ws:\n",
    "            # 发送 full client request\n",
    "            await ws.send(full_client_request)\n",
    "            res = await ws.recv()\n",
    "            result = parse_response(res)\n",
    "            if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                return result\n",
    "            for seq, (chunk, last) in enumerate(AsrWsClient.slice_data(wav_data, segment_size), 1):\n",
    "                # if no compression, comment this line\n",
    "                payload_bytes = gzip.compress(chunk)\n",
    "                audio_only_request = bytearray(generate_audio_default_header())\n",
    "                if last:\n",
    "                    audio_only_request = bytearray(generate_last_audio_default_header())\n",
    "                audio_only_request.extend((len(payload_bytes)).to_bytes(4, 'big'))  # payload size(4 bytes)\n",
    "                audio_only_request.extend(payload_bytes)  # payload\n",
    "                # 发送 audio-only client request\n",
    "                await ws.send(audio_only_request)\n",
    "                res = await ws.recv()\n",
    "                result = parse_response(res)\n",
    "                if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                    return result\n",
    "        return result\n",
    "\n",
    "    async def execute(self):\n",
    "        print(f\"Executing with audio_path: {self.audio_path}\")\n",
    "        with open(self.audio_path, mode=\"rb\") as _f:\n",
    "            data = _f.read()\n",
    "        audio_data = bytes(data)\n",
    "        if self.format == \"mp3\":\n",
    "            segment_size = self.mp3_seg_size\n",
    "            return await self.segment_data_processor(audio_data, segment_size)\n",
    "        if self.format != \"wav\":\n",
    "            raise Exception(\"format should in wav or mp3\")\n",
    "        nchannels, sampwidth, framerate, nframes, wav_len = read_wav_info(\n",
    "            audio_data)\n",
    "        size_per_sec = nchannels * sampwidth * framerate\n",
    "        segment_size = int(size_per_sec * self.seg_duration / 1000)\n",
    "        return await self.segment_data_processor(audio_data, segment_size)\n",
    "\n",
    "\n",
    "def execute_one(audio_item, cluster, **kwargs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param audio_item: {\"id\": xxx, \"path\": \"xxx\"}\n",
    "    :param cluster:集群名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert 'id' in audio_item\n",
    "    assert 'path' in audio_item\n",
    "    audio_id = audio_item['id']\n",
    "    audio_path = audio_item['path']\n",
    "    audio_type = AudioType.LOCAL\n",
    "    asr_http_client = AsrWsClient(\n",
    "        audio_path=audio_path,  # 确保这里使用了正确的 audio_path\n",
    "        cluster=cluster,\n",
    "        audio_type=audio_type,\n",
    "        **kwargs\n",
    "    )\n",
    "    result = asyncio.run(asr_http_client.execute())\n",
    "    return {\"id\": audio_id, \"path\": audio_path, \"result\": result}\n",
    "\n",
    "def test_one():\n",
    "    result = execute_one(\n",
    "        {\n",
    "            'id': 1,\n",
    "            'path': audio_path\n",
    "        },\n",
    "        cluster=cluster,\n",
    "        appid=appid,\n",
    "        token=token,\n",
    "        format=audio_format,\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"使用麦克风录制音频\"\"\"\n",
    "    print(\"开始录音...\")\n",
    "    audio = Audio()\n",
    "    \n",
    "    try:\n",
    "        # 显示录音倒计时\n",
    "        for i in range(3, 0, -1):\n",
    "            print(f\"录音将在 {i} 秒后开始...\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 开始录音\n",
    "        print(f\"正在录音，持续 {RECORD_DURATION} 秒...\")\n",
    "        audio.record(TEMP_AUDIO_FILE, RECORD_DURATION)\n",
    "        time.sleep(RECORD_DURATION + 0.5)  # 等待录音完成，多等待0.5秒确保文件保存\n",
    "        \n",
    "        # 检查文件是否成功创建\n",
    "        if os.path.exists(TEMP_AUDIO_FILE):\n",
    "            print(f\"录音完成，文件已保存为: {TEMP_AUDIO_FILE}\")\n",
    "            return TEMP_AUDIO_FILE\n",
    "        else:\n",
    "            print(\"录音文件创建失败\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"录音过程中发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "async def process_audio(audio_file):\n",
    "    \"\"\"处理录制的音频文件\"\"\"\n",
    "    print(f\"开始处理音频文件: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        result = execute_one(\n",
    "            {\n",
    "                'id': 1,\n",
    "                'path': audio_file\n",
    "            },\n",
    "            cluster=cluster,\n",
    "            appid=appid,\n",
    "            token=token,\n",
    "            format=\"wav\",\n",
    "        )\n",
    "        \n",
    "        print(\"Raw result:\", result)\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            if 'result' in result and isinstance(result['result'], dict):\n",
    "                payload_msg = result['result'].get('payload_msg', {})\n",
    "                if isinstance(payload_msg, dict):\n",
    "                    if payload_msg.get('code') == 1000:\n",
    "                        # 处理结果列表\n",
    "                        results = payload_msg.get('result', [])\n",
    "                        if results and isinstance(results, list):\n",
    "                            # 合并所有识别结果\n",
    "                            texts = [item.get('text', '') for item in results if isinstance(item, dict)]\n",
    "                            full_text = ''.join(texts)\n",
    "                            print(\"\\n识别结果:\")\n",
    "                            print(full_text)\n",
    "                            \n",
    "                            # 如果需要，也可以显示每段的置信度\n",
    "                            for i, item in enumerate(results, 1):\n",
    "                                if isinstance(item, dict):\n",
    "                                    confidence = item.get('confidence', 0)\n",
    "                                    print(f\"第{i}段置信度: {confidence}\")\n",
    "                        else:\n",
    "                            print(\"未获取到识别文本\")\n",
    "                    else:\n",
    "                        print(f\"\\n识别失败，错误码: {payload_msg.get('code')}\")\n",
    "                        print(f\"错误信息: {payload_msg.get('message', '无错误信息')}\")\n",
    "                else:\n",
    "                    print(\"无法解析 payload_msg\")\n",
    "            else:\n",
    "                print(\"无法获取别结果\")\n",
    "                print(\"完整返回数据:\", result)\n",
    "        else:\n",
    "            print(\"返回数据格式错误\")\n",
    "            print(\"返回数据:\", result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"处理音频时发生错误: {str(e)}\")\n",
    "        print(\"错误类型:\", type(e))\n",
    "        import traceback\n",
    "        print(\"错误堆栈:\", traceback.format_exc())\n",
    "    finally:\n",
    "        # 清理临时音频文件\n",
    "        try:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.remove(audio_file)\n",
    "                print(\"临时音频文件已删除\")\n",
    "        except Exception as e:\n",
    "            print(f\"删除时文件时发生错误: {e}\")\n",
    "\n",
    "# 初始化 Audio 和 GUI\n",
    "audio = Audio()\n",
    "gui = GUI()\n",
    "\n",
    "# 全局变量\n",
    "is_recording = False\n",
    "audio_file = \"/tmp/recording.wav\"\n",
    "recording_start_time = 0\n",
    "elapsed_time = 0\n",
    "time_text = None\n",
    "result_text = None\n",
    "running = True\n",
    "\n",
    "def print_status(message):\n",
    "    print(f\"[状态] {message}\")\n",
    "\n",
    "def update_gui():\n",
    "    global gui, time_text, result_text\n",
    "    gui.clear()\n",
    "    \n",
    "    # 添加标题\n",
    "    gui.draw_text(x=120, y=20, text=\"语音识别系统\", origin='center')\n",
    "    \n",
    "    # 添加时间显示\n",
    "    time_text = gui.draw_text(x=120, y=60, text=\"等待录音...\", origin='center')\n",
    "    \n",
    "    # 根据录音状态显示不同的按钮\n",
    "    if is_recording:\n",
    "        gui.add_button(x=120, y=120, w=160, h=60, text=\"正在录音\", origin='center', \n",
    "                      onclick=None, name=\"start_button\", state=\"disabled\")\n",
    "        gui.add_button(x=120, y=200, w=160, h=60, text=\"停止录音\", origin='center', \n",
    "                      onclick=stop_recording, name=\"stop_button\")\n",
    "    else:\n",
    "        gui.add_button(x=120, y=120, w=160, h=60, text=\"开始录音\", origin='center', \n",
    "                      onclick=start_recording, name=\"start_button\")\n",
    "        gui.add_button(x=120, y=200, w=160, h=60, text=\"停止录音\", origin='center', \n",
    "                      onclick=None, name=\"stop_button\", state=\"disabled\")\n",
    "    \n",
    "    # 添加退出按钮\n",
    "    gui.add_button(x=120, y=280, w=160, h=60, text=\"退出程序\", origin='center', \n",
    "                  onclick=exit_program, name=\"exit_button\")\n",
    "    \n",
    "    # 添加结果显示区域\n",
    "    result_text = gui.draw_text(x=120, y=360, text=\"\", origin='center')\n",
    "\n",
    "def update_time_text():\n",
    "    global time_text\n",
    "    if time_text and is_recording:\n",
    "        time_text.text = f\"录音时长: {elapsed_time} 秒\"\n",
    "    elif time_text:\n",
    "        time_text.text = \"等待录音...\"\n",
    "\n",
    "def update_result_text(text):\n",
    "    global result_text\n",
    "    if result_text:\n",
    "        result_text.text = text\n",
    "\n",
    "def start_recording():\n",
    "    global is_recording, recording_start_time, elapsed_time\n",
    "    if not is_recording:\n",
    "        print_status(\"开始录音\")\n",
    "        try:\n",
    "            audio.start_record(audio_file)\n",
    "            is_recording = True\n",
    "            recording_start_time = time.time()\n",
    "            elapsed_time = 0\n",
    "            update_gui()\n",
    "            update_result_text(\"录音中...\")\n",
    "        except Exception as e:\n",
    "            print_status(f\"开始录音时发生错误: {e}\")\n",
    "            update_result_text(f\"错误: {str(e)}\")\n",
    "\n",
    "def stop_recording():\n",
    "    global is_recording, elapsed_time\n",
    "    if is_recording:\n",
    "        print_status(\"停止录音\")\n",
    "        try:\n",
    "            audio.stop_record()\n",
    "            is_recording = False\n",
    "            update_gui()\n",
    "            update_result_text(\"正在识别...\")\n",
    "            threading.Thread(target=process_audio, daemon=True).start()\n",
    "        except Exception as e:\n",
    "            print_status(f\"停止录音时发生错误: {e}\")\n",
    "            update_result_text(f\"错误: {str(e)}\")\n",
    "\n",
    "def process_audio():\n",
    "    print_status(f\"开始处理音频文件: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        result = execute_one(\n",
    "            {\n",
    "                'id': 1,\n",
    "                'path': audio_file\n",
    "            },\n",
    "            cluster=cluster,\n",
    "            appid=appid,\n",
    "            token=token,\n",
    "            format=\"wav\",\n",
    "        )\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            if 'result' in result and isinstance(result['result'], dict):\n",
    "                payload_msg = result['result'].get('payload_msg', {})\n",
    "                if isinstance(payload_msg, dict):\n",
    "                    if payload_msg.get('code') == 1000:\n",
    "                        results = payload_msg.get('result', [])\n",
    "                        if results and isinstance(results, list):\n",
    "                            texts = [item.get('text', '') for item in results if isinstance(item, dict)]\n",
    "                            full_text = ''.join(texts)\n",
    "                            print_status(f\"识别结果: {full_text}\")\n",
    "                            update_result_text(f\"识别结果: {full_text}\")\n",
    "                    else:\n",
    "                        error_msg = f\"识别失败 (错误码: {payload_msg.get('code')})\"\n",
    "                        print_status(error_msg)\n",
    "                        update_result_text(error_msg)\n",
    "                else:\n",
    "                    update_result_text(\"无法解析识别结果\")\n",
    "            else:\n",
    "                update_result_text(\"无法获取识别结果\")\n",
    "        else:\n",
    "            update_result_text(\"返回数据格式错误\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print_status(f\"处理音频时发生错误: {e}\")\n",
    "        update_result_text(f\"错误: {str(e)}\")\n",
    "    finally:\n",
    "        try:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.remove(audio_file)\n",
    "                print_status(\"临时音频文件已删除\")\n",
    "        except Exception as e:\n",
    "            print_status(f\"删除临时文件时发生错误: {e}\")\n",
    "\n",
    "def exit_program():\n",
    "    global running\n",
    "    running = False\n",
    "    print_status(\"程序正在退出...\")\n",
    "    gui.clear()\n",
    "    exit()\n",
    "\n",
    "def main():\n",
    "    global elapsed_time, running\n",
    "    \n",
    "    update_gui()\n",
    "    print_status(\"程序已启动，等待操作...\")\n",
    "\n",
    "    # 主循环\n",
    "    while running:\n",
    "        try:\n",
    "            if is_recording:\n",
    "                current_time = time.time()\n",
    "                new_elapsed_time = int(current_time - recording_start_time)\n",
    "                if new_elapsed_time != elapsed_time:\n",
    "                    elapsed_time = new_elapsed_time\n",
    "                    update_time_text()\n",
    "            time.sleep(0.1)\n",
    "        except Exception as e:\n",
    "            print_status(f\"主循环发生错误: {e}\")\n",
    "            time.sleep(1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print_status(\"程序被用户中断\")\n",
    "    except Exception as e:\n",
    "        print_status(f\"程序发生错误: {e}\")\n",
    "    finally:\n",
    "        print_status(\"程序结束\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cfce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "使用的是流式录音API，接下来实现流式实时显示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f631b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUI is cleared because of reinit\n",
      "[状态] 程序已启动，等待操作...\n",
      "[状态] 开始录音\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.7/threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_969/2229986343.py\", line 486, in run_recognition\n",
      "    loop.run_until_complete(process_audio_stream())\n",
      "NameError: name 'process_audio_stream' is not defined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "requires Python 3.6 or later\n",
    "\n",
    "pip install asyncio\n",
    "pip install websockets\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import base64\n",
    "import gzip\n",
    "import hmac\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import uuid\n",
    "import wave\n",
    "from enum import Enum\n",
    "from hashlib import sha256\n",
    "from io import BytesIO\n",
    "from typing import List\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import websockets\n",
    "from unihiker import Audio, GUI\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import threading\n",
    "import queue\n",
    "import io\n",
    "import tempfile\n",
    "\n",
    "# 火山平台API配置\n",
    "appid = \"4166554764\"    # 项目的 appid\n",
    "token = \"ggmUTHHMXio-nJlKMkRvqEgkcWyfDK0K\"    # 项目的 token\n",
    "cluster = \"volcengine_streaming_common\"  # 请求的集群\n",
    "\n",
    "# 音频采集设置\n",
    "RECORD_DURATION = 6  # 录音时长(秒)\n",
    "TEMP_AUDIO_FILE = \"temp_recording.wav\"  # 临时音频文件名\n",
    "\n",
    "PROTOCOL_VERSION = 0b0001\n",
    "DEFAULT_HEADER_SIZE = 0b0001\n",
    "\n",
    "PROTOCOL_VERSION_BITS = 4\n",
    "HEADER_BITS = 4\n",
    "MESSAGE_TYPE_BITS = 4\n",
    "MESSAGE_TYPE_SPECIFIC_FLAGS_BITS = 4\n",
    "MESSAGE_SERIALIZATION_BITS = 4\n",
    "MESSAGE_COMPRESSION_BITS = 4\n",
    "RESERVED_BITS = 8\n",
    "\n",
    "# Message Type:\n",
    "CLIENT_FULL_REQUEST = 0b0001\n",
    "CLIENT_AUDIO_ONLY_REQUEST = 0b0010\n",
    "SERVER_FULL_RESPONSE = 0b1001\n",
    "SERVER_ACK = 0b1011\n",
    "SERVER_ERROR_RESPONSE = 0b1111\n",
    "\n",
    "# Message Type Specific Flags\n",
    "NO_SEQUENCE = 0b0000  # no check sequence\n",
    "POS_SEQUENCE = 0b0001\n",
    "NEG_SEQUENCE = 0b0010\n",
    "NEG_SEQUENCE_1 = 0b0011\n",
    "\n",
    "# Message Serialization\n",
    "NO_SERIALIZATION = 0b0000\n",
    "JSON = 0b0001\n",
    "THRIFT = 0b0011\n",
    "CUSTOM_TYPE = 0b1111\n",
    "\n",
    "# Message Compression\n",
    "NO_COMPRESSION = 0b0000\n",
    "GZIP = 0b0001\n",
    "CUSTOM_COMPRESSION = 0b1111\n",
    "\n",
    "\n",
    "def generate_header(\n",
    "    version=PROTOCOL_VERSION,\n",
    "    message_type=CLIENT_FULL_REQUEST,\n",
    "    message_type_specific_flags=NO_SEQUENCE,\n",
    "    serial_method=JSON,\n",
    "    compression_type=GZIP,\n",
    "    reserved_data=0x00,\n",
    "    extension_header=bytes()\n",
    "):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    \"\"\"\n",
    "    header = bytearray()\n",
    "    header_size = int(len(extension_header) / 4) + 1\n",
    "    header.append((version << 4) | header_size)\n",
    "    header.append((message_type << 4) | message_type_specific_flags)\n",
    "    header.append((serial_method << 4) | compression_type)\n",
    "    header.append(reserved_data)\n",
    "    header.extend(extension_header)\n",
    "    return header\n",
    "\n",
    "\n",
    "def generate_full_default_header():\n",
    "    return generate_header()\n",
    "\n",
    "\n",
    "def generate_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_last_audio_default_header():\n",
    "    return generate_header(\n",
    "        message_type=CLIENT_AUDIO_ONLY_REQUEST,\n",
    "        message_type_specific_flags=NEG_SEQUENCE\n",
    "    )\n",
    "\n",
    "def parse_response(res):\n",
    "    \"\"\"\n",
    "    protocol_version(4 bits), header_size(4 bits),\n",
    "    message_type(4 bits), message_type_specific_flags(4 bits)\n",
    "    serialization_method(4 bits) message_compression(4 bits)\n",
    "    reserved （8bits) 保留字段\n",
    "    header_extensions 扩展头(大小等于 8 * 4 * (header_size - 1) )\n",
    "    payload 类似与http 请求体\n",
    "    \"\"\"\n",
    "    protocol_version = res[0] >> 4\n",
    "    header_size = res[0] & 0x0f\n",
    "    message_type = res[1] >> 4\n",
    "    message_type_specific_flags = res[1] & 0x0f\n",
    "    serialization_method = res[2] >> 4\n",
    "    message_compression = res[2] & 0x0f\n",
    "    reserved = res[3]\n",
    "    header_extensions = res[4:header_size * 4]\n",
    "    payload = res[header_size * 4:]\n",
    "    result = {}\n",
    "    payload_msg = None\n",
    "    payload_size = 0\n",
    "    if message_type == SERVER_FULL_RESPONSE:\n",
    "        payload_size = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        payload_msg = payload[4:]\n",
    "    elif message_type == SERVER_ACK:\n",
    "        seq = int.from_bytes(payload[:4], \"big\", signed=True)\n",
    "        result['seq'] = seq\n",
    "        if len(payload) >= 8:\n",
    "            payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "            payload_msg = payload[8:]\n",
    "    elif message_type == SERVER_ERROR_RESPONSE:\n",
    "        code = int.from_bytes(payload[:4], \"big\", signed=False)\n",
    "        result['code'] = code\n",
    "        payload_size = int.from_bytes(payload[4:8], \"big\", signed=False)\n",
    "        payload_msg = payload[8:]\n",
    "    if payload_msg is None:\n",
    "        return result\n",
    "    if message_compression == GZIP:\n",
    "        payload_msg = gzip.decompress(payload_msg)\n",
    "    if serialization_method == JSON:\n",
    "        payload_msg = json.loads(str(payload_msg, \"utf-8\"))\n",
    "    elif serialization_method != NO_SERIALIZATION:\n",
    "        payload_msg = str(payload_msg, \"utf-8\")\n",
    "    result['payload_msg'] = payload_msg\n",
    "    result['payload_size'] = payload_size\n",
    "    return result\n",
    "\n",
    "\n",
    "def read_wav_info(data: bytes = None) -> (int, int, int, int, int):\n",
    "    with BytesIO(data) as _f:\n",
    "        wave_fp = wave.open(_f, 'rb')\n",
    "        nchannels, sampwidth, framerate, nframes = wave_fp.getparams()[:4]\n",
    "        wave_bytes = wave_fp.readframes(nframes)\n",
    "    return nchannels, sampwidth, framerate, nframes, len(wave_bytes)\n",
    "\n",
    "class AudioType(Enum):\n",
    "    LOCAL = 1  # 使用本地音频文件\n",
    "\n",
    "class AsrWsClient:\n",
    "    def __init__(self, audio_path, cluster, **kwargs):\n",
    "        print(f\"Initializing AsrWsClient with audio_path: {audio_path}\")\n",
    "        self.audio_path = audio_path\n",
    "        self.cluster = cluster\n",
    "        self.success_code = 1000  # success code, default is 1000\n",
    "        self.seg_duration = int(kwargs.get(\"seg_duration\", 15000))\n",
    "        self.nbest = int(kwargs.get(\"nbest\", 1))\n",
    "        self.appid = kwargs.get(\"appid\", \"\")\n",
    "        self.token = kwargs.get(\"token\", \"\")\n",
    "        self.ws_url = kwargs.get(\"ws_url\", \"wss://openspeech.bytedance.com/api/v2/asr\")\n",
    "        self.uid = kwargs.get(\"uid\", \"streaming_asr_demo\")\n",
    "        self.workflow = kwargs.get(\"workflow\", \"audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate\")\n",
    "        self.show_language = kwargs.get(\"show_language\", False)\n",
    "        self.show_utterances = kwargs.get(\"show_utterances\", False)\n",
    "        self.result_type = kwargs.get(\"result_type\", \"full\")\n",
    "        self.format = kwargs.get(\"format\", \"wav\")\n",
    "        self.rate = kwargs.get(\"sample_rate\", 16000)\n",
    "        self.language = kwargs.get(\"language\", \"zh-CN\")\n",
    "        self.bits = kwargs.get(\"bits\", 16)\n",
    "        self.channel = kwargs.get(\"channel\", 1)\n",
    "        self.codec = kwargs.get(\"codec\", \"raw\")\n",
    "        self.audio_type = kwargs.get(\"audio_type\", AudioType.LOCAL)\n",
    "        self.secret = kwargs.get(\"secret\", \"access_secret\")\n",
    "        self.auth_method = kwargs.get(\"auth_method\", \"token\")\n",
    "        self.mp3_seg_size = int(kwargs.get(\"mp3_seg_size\", 10000))\n",
    "        self.on_message = None  # 添加回调函数属性\n",
    "\n",
    "    def construct_request(self, reqid):\n",
    "        req = {\n",
    "            'app': {\n",
    "                'appid': self.appid,\n",
    "                'cluster': self.cluster,\n",
    "                'token': self.token,\n",
    "            },\n",
    "            'user': {\n",
    "                'uid': self.uid\n",
    "            },\n",
    "            'request': {\n",
    "                'reqid': reqid,\n",
    "                'nbest': self.nbest,\n",
    "                'workflow': self.workflow,\n",
    "                'show_language': self.show_language,\n",
    "                'show_utterances': self.show_utterances,\n",
    "                'result_type': self.result_type,\n",
    "                \"sequence\": 1\n",
    "            },\n",
    "            'audio': {\n",
    "                'format': self.format,\n",
    "                'rate': self.rate,\n",
    "                'language': self.language,\n",
    "                'bits': self.bits,\n",
    "                'channel': self.channel,\n",
    "                'codec': self.codec\n",
    "            }\n",
    "        }\n",
    "        return req\n",
    "\n",
    "    @staticmethod\n",
    "    def slice_data(data: bytes, chunk_size: int) -> (list, bool):\n",
    "        \"\"\"\n",
    "        slice data\n",
    "        :param data: wav data\n",
    "        :param chunk_size: the segment size in one request\n",
    "        :return: segment data, last flag\n",
    "        \"\"\"\n",
    "        data_len = len(data)\n",
    "        offset = 0\n",
    "        while offset + chunk_size < data_len:\n",
    "            yield data[offset: offset + chunk_size], False\n",
    "            offset += chunk_size\n",
    "        else:\n",
    "            yield data[offset: data_len], True\n",
    "\n",
    "    def _real_processor(self, request_params: dict) -> dict:\n",
    "        pass\n",
    "\n",
    "    def token_auth(self):\n",
    "        return {'Authorization': 'Bearer; {}'.format(self.token)}\n",
    "\n",
    "    def signature_auth(self, data):\n",
    "        header_dicts = {\n",
    "            'Custom': 'auth_custom',\n",
    "        }\n",
    "\n",
    "        url_parse = urlparse(self.ws_url)\n",
    "        input_str = 'GET {} HTTP/1.1\\n'.format(url_parse.path)\n",
    "        auth_headers = 'Custom'\n",
    "        for header in auth_headers.split(','):\n",
    "            input_str += '{}\\n'.format(header_dicts[header])\n",
    "        input_data = bytearray(input_str, 'utf-8')\n",
    "        input_data += data\n",
    "        mac = base64.urlsafe_b64encode(\n",
    "            hmac.new(self.secret.encode('utf-8'), input_data, digestmod=sha256).digest())\n",
    "        header_dicts['Authorization'] = 'HMAC256; access_token=\"{}\"; mac=\"{}\"; h=\"{}\"'.format(self.token,\n",
    "                                                                                              str(mac, 'utf-8'), auth_headers)\n",
    "        return header_dicts\n",
    "\n",
    "    async def segment_data_processor(self, wav_data: bytes, segment_size: int):\n",
    "        reqid = str(uuid.uuid4())\n",
    "        request_params = self.construct_request(reqid)\n",
    "        payload_bytes = str.encode(json.dumps(request_params))\n",
    "        payload_bytes = gzip.compress(payload_bytes)\n",
    "        full_client_request = bytearray(generate_full_default_header())\n",
    "        full_client_request.extend((len(payload_bytes)).to_bytes(4, 'big'))\n",
    "        full_client_request.extend(payload_bytes)\n",
    "        \n",
    "        header = None\n",
    "        if self.auth_method == \"token\":\n",
    "            header = self.token_auth()\n",
    "        elif self.auth_method == \"signature\":\n",
    "            header = self.signature_auth(full_client_request)\n",
    "            \n",
    "        async with websockets.connect(self.ws_url, extra_headers=header, max_size=1000000000) as ws:\n",
    "            await ws.send(full_client_request)\n",
    "            res = await ws.recv()\n",
    "            result = parse_response(res)\n",
    "            \n",
    "            # 处理第一个响应\n",
    "            if self.on_message:\n",
    "                self.on_message(result)\n",
    "                \n",
    "            if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                return result\n",
    "                \n",
    "            for seq, (chunk, last) in enumerate(AsrWsClient.slice_data(wav_data, segment_size), 1):\n",
    "                payload_bytes = gzip.compress(chunk)\n",
    "                audio_only_request = bytearray(generate_audio_default_header())\n",
    "                if last:\n",
    "                    audio_only_request = bytearray(generate_last_audio_default_header())\n",
    "                audio_only_request.extend((len(payload_bytes)).to_bytes(4, 'big'))\n",
    "                audio_only_request.extend(payload_bytes)\n",
    "                \n",
    "                await ws.send(audio_only_request)\n",
    "                res = await ws.recv()\n",
    "                result = parse_response(res)\n",
    "                \n",
    "                # 处理每个分片的响应\n",
    "                if self.on_message:\n",
    "                    self.on_message(result)\n",
    "                    \n",
    "                if 'payload_msg' in result and result['payload_msg']['code'] != self.success_code:\n",
    "                    return result\n",
    "                    \n",
    "        return result\n",
    "\n",
    "    async def execute(self):\n",
    "        print(f\"Executing with audio_path: {self.audio_path}\")\n",
    "        with open(self.audio_path, mode=\"rb\") as _f:\n",
    "            data = _f.read()\n",
    "        audio_data = bytes(data)\n",
    "        if self.format == \"mp3\":\n",
    "            segment_size = self.mp3_seg_size\n",
    "            return await self.segment_data_processor(audio_data, segment_size)\n",
    "        if self.format != \"wav\":\n",
    "            raise Exception(\"format should in wav or mp3\")\n",
    "        nchannels, sampwidth, framerate, nframes, wav_len = read_wav_info(\n",
    "            audio_data)\n",
    "        size_per_sec = nchannels * sampwidth * framerate\n",
    "        segment_size = int(size_per_sec * self.seg_duration / 1000)\n",
    "        return await self.segment_data_processor(audio_data, segment_size)\n",
    "\n",
    "\n",
    "def execute_one(audio_item, cluster, **kwargs):\n",
    "    \"\"\"\n",
    "\n",
    "    :param audio_item: {\"id\": xxx, \"path\": \"xxx\"}\n",
    "    :param cluster:集群名称\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert 'id' in audio_item\n",
    "    assert 'path' in audio_item\n",
    "    audio_id = audio_item['id']\n",
    "    audio_path = audio_item['path']\n",
    "    audio_type = AudioType.LOCAL\n",
    "    asr_http_client = AsrWsClient(\n",
    "        audio_path=audio_path,  # 确保这里使用了正确的 audio_path\n",
    "        cluster=cluster,\n",
    "        audio_type=audio_type,\n",
    "        **kwargs\n",
    "    )\n",
    "    result = asyncio.run(asr_http_client.execute())\n",
    "    return {\"id\": audio_id, \"path\": audio_path, \"result\": result}\n",
    "\n",
    "def test_one():\n",
    "    result = execute_one(\n",
    "        {\n",
    "            'id': 1,\n",
    "            'path': audio_path\n",
    "        },\n",
    "        cluster=cluster,\n",
    "        appid=appid,\n",
    "        token=token,\n",
    "        format=audio_format,\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "def record_audio():\n",
    "    \"\"\"使用麦克风录制音频\"\"\"\n",
    "    print(\"开始录音...\")\n",
    "    audio = Audio()\n",
    "    \n",
    "    try:\n",
    "        # 显示录音倒计时\n",
    "        for i in range(3, 0, -1):\n",
    "            print(f\"录音将在 {i} 秒后开始...\")\n",
    "            time.sleep(1)\n",
    "        \n",
    "        # 开始录音\n",
    "        print(f\"正在录音，持续 {RECORD_DURATION} 秒...\")\n",
    "        audio.record(TEMP_AUDIO_FILE, RECORD_DURATION)\n",
    "        time.sleep(RECORD_DURATION + 0.5)  # 等待录音完成，等待0.5秒确保文件保存\n",
    "        \n",
    "        # 检查文件是否成功创建\n",
    "        if os.path.exists(TEMP_AUDIO_FILE):\n",
    "            print(f\"录音完成，文件已保存为: {TEMP_AUDIO_FILE}\")\n",
    "            return TEMP_AUDIO_FILE\n",
    "        else:\n",
    "            print(\"录音文件创建失败\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"录音过程中发生错误: {e}\")\n",
    "        return None\n",
    "\n",
    "async def process_audio(audio_file):\n",
    "    \"\"\"处理录制的音频文件\"\"\"\n",
    "    print(f\"开始处理音频文件: {audio_file}\")\n",
    "    \n",
    "    try:\n",
    "        result = execute_one(\n",
    "            {\n",
    "                'id': 1,\n",
    "                'path': audio_file\n",
    "            },\n",
    "            cluster=cluster,\n",
    "            appid=appid,\n",
    "            token=token,\n",
    "            format=\"wav\",\n",
    "        )\n",
    "        \n",
    "        print(\"Raw result:\", result)\n",
    "        \n",
    "        if isinstance(result, dict):\n",
    "            if 'result' in result and isinstance(result['result'], dict):\n",
    "                payload_msg = result['result'].get('payload_msg', {})\n",
    "                if isinstance(payload_msg, dict):\n",
    "                    if payload_msg.get('code') == 1000:\n",
    "                        # 处理结果列表\n",
    "                        results = payload_msg.get('result', [])\n",
    "                        if results and isinstance(results, list):\n",
    "                            # 合并所有识别结果\n",
    "                            texts = [item.get('text', '') for item in results if isinstance(item, dict)]\n",
    "                            full_text = ''.join(texts)\n",
    "                            print(\"\\n识别结果:\")\n",
    "                            print(full_text)\n",
    "                            \n",
    "                            # 如果需要，也可以显示每段的置信度\n",
    "                            for i, item in enumerate(results, 1):\n",
    "                                if isinstance(item, dict):\n",
    "                                    confidence = item.get('confidence', 0)\n",
    "                                    print(f\"第{i}段置信度: {confidence}\")\n",
    "                        else:\n",
    "                            print(\"未获取到识别文本\")\n",
    "                    else:\n",
    "                        print(f\"\\n识别失败，错误码: {payload_msg.get('code')}\")\n",
    "                        print(f\"错误信息: {payload_msg.get('message', '无错误信息')}\")\n",
    "                else:\n",
    "                    print(\"无法解析 payload_msg\")\n",
    "            else:\n",
    "                print(\"无获取别结果\")\n",
    "                print(\"完整返回数据:\", result)\n",
    "        else:\n",
    "            print(\"返回数据格式错误\")\n",
    "            print(\"返回数据:\", result)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"处理音频时发生错误: {str(e)}\")\n",
    "        print(\"错误类型:\", type(e))\n",
    "        import traceback\n",
    "        print(\"错误堆栈:\", traceback.format_exc())\n",
    "    finally:\n",
    "        # 清理临时音频文\n",
    "        try:\n",
    "            if os.path.exists(audio_file):\n",
    "                os.remove(audio_file)\n",
    "                print(\"临时音频文件已删除\")\n",
    "        except Exception as e:\n",
    "            print(f\"删除时文件时发生错误: {e}\")\n",
    "\n",
    "# 全局变量\n",
    "gui = GUI()\n",
    "audio = Audio()\n",
    "is_recording = False\n",
    "recording_start_time = 0\n",
    "elapsed_time = 0\n",
    "time_text = None\n",
    "result_text = None\n",
    "\n",
    "# 临时文件相关\n",
    "TEMP_DIR = tempfile.gettempdir()\n",
    "current_audio_file = None\n",
    "is_processing = False\n",
    "recognition_task = None\n",
    "\n",
    "# 在全局作用域定义 run_recognition 函数\n",
    "def run_recognition():\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    loop.run_until_complete(process_audio_stream())\n",
    "    loop.close()\n",
    "\n",
    "def start_recording():\n",
    "    global is_recording, recording_start_time, elapsed_time, is_processing\n",
    "    global current_audio_file, recognition_task\n",
    "    \n",
    "    if not is_recording:\n",
    "        print_status(\"开始录音\")\n",
    "        try:\n",
    "            # 创建临时文件\n",
    "            current_audio_file = os.path.join(TEMP_DIR, f\"recording_{int(time.time())}.wav\")\n",
    "            \n",
    "            # 启动录音\n",
    "            audio.start_record(current_audio_file)\n",
    "            is_recording = True\n",
    "            is_processing = True\n",
    "            recording_start_time = time.time()\n",
    "            elapsed_time = 0\n",
    "            update_gui()\n",
    "            \n",
    "            # 启动语音识别线程\n",
    "            recognition_task = threading.Thread(target=run_recognition)\n",
    "            recognition_task.daemon = True\n",
    "            recognition_task.start()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print_status(f\"开始录音时发生错误: {e}\")\n",
    "            is_recording = False\n",
    "            is_processing = False\n",
    "\n",
    "def stop_recording():\n",
    "    global is_recording, is_processing, current_audio_file\n",
    "    if is_recording:\n",
    "        print_status(\"停止录音\")\n",
    "        try:\n",
    "            is_recording = False\n",
    "            is_processing = False\n",
    "            audio.stop_record()\n",
    "            \n",
    "            # 等待识别任务结束\n",
    "            if recognition_task and recognition_task.is_alive():\n",
    "                recognition_task.join(timeout=2)\n",
    "            \n",
    "            # 清理临时文件\n",
    "            if current_audio_file and os.path.exists(current_audio_file):\n",
    "                os.remove(current_audio_file)\n",
    "                current_audio_file = None\n",
    "            \n",
    "            update_gui()\n",
    "        except Exception as e:\n",
    "            print_status(f\"停止录音时发生错误: {e}\")\n",
    "\n",
    "def update_result_text(text):\n",
    "    global result_text\n",
    "    if result_text:\n",
    "        try:\n",
    "            # 将长文本分成多行显示\n",
    "            max_chars_per_line = 20  # 每行最大字符数\n",
    "            display_lines = []\n",
    "            \n",
    "            # 分行处理文本\n",
    "            current_line = \"\"\n",
    "            for char in text:\n",
    "                current_line += char\n",
    "                if len(current_line) >= max_chars_per_line:\n",
    "                    display_lines.append(current_line)\n",
    "                    current_line = \"\"\n",
    "            if current_line:\n",
    "                display_lines.append(current_line)\n",
    "            \n",
    "            # 更新显示\n",
    "            result_text.text = \"\\n\".join(display_lines)\n",
    "            # 强制更新 GUI\n",
    "            gui.update()\n",
    "        except Exception as e:\n",
    "            print_status(f\"更新文本显示时发生错误: {e}\")\n",
    "\n",
    "def update_gui():\n",
    "    global gui, time_text, result_text\n",
    "    try:\n",
    "        gui.clear()\n",
    "        \n",
    "        # 添加标题\n",
    "        gui.draw_text(x=120, y=20, text=\"语音识别系统\", origin='center')\n",
    "        \n",
    "        # 添加时间显示\n",
    "        time_text = gui.draw_text(x=120, y=50, text=\"等待录音...\", origin='center')\n",
    "        \n",
    "        # 按钮布局\n",
    "        if is_recording:\n",
    "            gui.add_button(x=120, y=100, w=160, h=50, text=\"正在录音\", origin='center', \n",
    "                          onclick=None, name=\"start_button\", state=\"disabled\")\n",
    "            gui.add_button(x=120, y=160, w=160, h=50, text=\"停止录音\", origin='center', \n",
    "                          onclick=stop_recording, name=\"stop_button\")\n",
    "        else:\n",
    "            gui.add_button(x=120, y=100, w=160, h=50, text=\"开始录音\", origin='center', \n",
    "                          onclick=start_recording, name=\"start_button\")\n",
    "            gui.add_button(x=120, y=160, w=160, h=50, text=\"停止录音\", origin='center', \n",
    "                          onclick=None, name=\"stop_button\", state=\"disabled\")\n",
    "        \n",
    "        # 退出按钮\n",
    "        gui.add_button(x=120, y=220, w=160, h=50, text=\"退出程序\", origin='center', \n",
    "                      onclick=exit_program, name=\"exit_button\")\n",
    "        \n",
    "        # 结果显示区域\n",
    "        result_text = gui.draw_text(x=120, y=300, text=\"\", origin='center')\n",
    "    except Exception as e:\n",
    "        print_status(f\"更新GUI时发生错误: {e}\")\n",
    "\n",
    "def print_status(msg):\n",
    "    print(f\"[状态] {msg}\")\n",
    "\n",
    "def exit_program():\n",
    "    global is_recording, is_processing\n",
    "    is_recording = False\n",
    "    is_processing = False\n",
    "    if recognition_task and recognition_task.is_alive():\n",
    "        recognition_task.join(timeout=2)\n",
    "    gui.clear()\n",
    "    exit()\n",
    "\n",
    "# 初始化 GUI\n",
    "update_gui()\n",
    "print_status(\"程序已启动，等待操作...\")\n",
    "\n",
    "# 启动主循环\n",
    "while True:\n",
    "    if is_recording:\n",
    "        elapsed_time = int(time.time() - recording_start_time)\n",
    "        minutes = elapsed_time // 60\n",
    "        seconds = elapsed_time % 60\n",
    "        if time_text:\n",
    "            time_text.text = f\"录音时间: {minutes:02d}:{seconds:02d}\"\n",
    "    time.sleep(0.1)\n",
    "\n",
    "async def process_audio_stream():\n",
    "    global current_audio_file, is_processing\n",
    "    print_status(\"开始语音识别流程\")\n",
    "    \n",
    "    try:\n",
    "        # 构建请求参数\n",
    "        reqid = str(uuid.uuid4())\n",
    "        request_params = {\n",
    "            \"app\": {\n",
    "                \"appid\": appid,\n",
    "                \"token\": token,\n",
    "                \"cluster\": cluster\n",
    "            },\n",
    "            \"user\": {\n",
    "                \"uid\": \"streaming_asr_demo\"\n",
    "            },\n",
    "            \"audio\": {\n",
    "                \"format\": \"wav\",\n",
    "                \"channel\": 1,\n",
    "                \"rate\": 16000,\n",
    "                \"bits\": 16\n",
    "            },\n",
    "            \"request\": {\n",
    "                \"reqid\": reqid,\n",
    "                \"sequence\": 1,\n",
    "                \"workflow\": \"audio_in,resample,partition,vad,fe,decode,itn,nlu_punctuate\",\n",
    "                \"show_utterances\": True,\n",
    "                \"result_type\": \"single\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "        print_status(f\"连接WebSocket服务器...\")\n",
    "        async with websockets.connect(\n",
    "            'wss://openspeech.bytedance.com/api/v2/asr',\n",
    "            extra_headers={'Authorization': f'Bearer {token}'}\n",
    "        ) as ws:\n",
    "            print_status(\"WebSocket连接成功\")\n",
    "            \n",
    "            # 读取并发送音频数据\n",
    "            chunk_size = 3200  # 每次处理100ms的音频数据\n",
    "            last_size = 0\n",
    "            \n",
    "            while is_processing and current_audio_file:\n",
    "                try:\n",
    "                    # 检查文件大小是否有变化\n",
    "                    if os.path.exists(current_audio_file):\n",
    "                        current_size = os.path.getsize(current_audio_file)\n",
    "                        if current_size > last_size:\n",
    "                            print_status(f\"读取新音频数据: {current_size - last_size} 字节\")\n",
    "                            with open(current_audio_file, 'rb') as f:\n",
    "                                f.seek(last_size)\n",
    "                                audio_data = f.read(chunk_size)\n",
    "                                \n",
    "                                if audio_data:\n",
    "                                    print_status(f\"发送音频数据: {len(audio_data)} 字节\")\n",
    "                                    # 压缩音频数据\n",
    "                                    compressed_chunk = gzip.compress(audio_data)\n",
    "                                    \n",
    "                                    # 构建音频请求\n",
    "                                    audio_request = bytearray([\n",
    "                                        0x11,  # version 1, header size 1\n",
    "                                        0x20,  # audio only request, no flags\n",
    "                                        0x01,  # no serialization, Gzip compression\n",
    "                                        0x00   # reserved\n",
    "                                    ])\n",
    "                                    audio_request.extend((len(compressed_chunk)).to_bytes(4, 'big'))\n",
    "                                    audio_request.extend(compressed_chunk)\n",
    "                                    \n",
    "                                    # 发送音频数据\n",
    "                                    await ws.send(audio_request)\n",
    "                                    print_status(\"等待识别结果...\")\n",
    "                                    \n",
    "                                    # 接收识别结果\n",
    "                                    response = await ws.recv()\n",
    "                                    result = parse_response(response)\n",
    "                                    print_status(f\"收到响应: {result}\")\n",
    "                                    \n",
    "                                    # 处理识别结果\n",
    "                                    if result and 'payload_msg' in result:\n",
    "                                        payload_msg = result['payload_msg']\n",
    "                                        print_status(f\"响应内容: {payload_msg}\")\n",
    "                                        if payload_msg.get('code') == 1000:\n",
    "                                            results = payload_msg.get('result', [])\n",
    "                                            if results and isinstance(results, list):\n",
    "                                                for res in results:\n",
    "                                                    text = res.get('text', '')\n",
    "                                                    if text:\n",
    "                                                        print_status(f\"实时识别: {text}\")\n",
    "                                                        update_result_text(f\"识别结果:\\n{text}\")\n",
    "                                    \n",
    "                                    last_size = current_size\n",
    "                    \n",
    "                    await asyncio.sleep(0.1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print_status(f\"处理音频流时发生错误: {e}\")\n",
    "                    break\n",
    "            \n",
    "            print_status(\"发送结束标记\")\n",
    "            # 发送结束标记\n",
    "            last_request = bytearray([\n",
    "                0x11,  # version 1, header size 1\n",
    "                0x22,  # audio only request, end flag\n",
    "                0x01,  # no serialization, Gzip compression\n",
    "                0x00   # reserved\n",
    "            ])\n",
    "            last_request.extend((0).to_bytes(4, 'big'))\n",
    "            await ws.send(last_request)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print_status(f\"语音识别过程发生错误: {e}\")\n",
    "    finally:\n",
    "        is_processing = False\n",
    "        print_status(\"语音识别流程结束\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d891d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
